\chapter{Conclusion}
\label{Conclusion}
Overall, it appears that the LLM does actually perform better than the LSTM on certain tasks for some datasets. It appears that it tends to do very well on complex classification tasks in the datasets we experimented on. Initially it seemed like one of the networks might be better at predicting a single user's behavior in the natural datasets, but both of the networks had one ``successful'' dataset in predicting a single user's behavior (Freecodecamp and Reddit Threads) vs. multiple user's behavior (Dota Class and Reddit Comments). It seems that the LLM doesn't always capture the underlying structure of the data. If nothing else, it does seem to be a good tool for analyzing the structure of the dataset itself. In other words, does the sequence behave like a series of log-linear spaced memory scales.
\\\\ Following the results of our trials, it seems that the LLM would be an excellent addition to a toolbox of networks for use with event sequences. We'd love to say that the LLM is always the better choice for event sequence data, but there are certainy cases where the LSTM performs better. In further works, we would hope to find more applications and datasets to test the networks on. This would allow us to further determine the strengths of the network. It could also be interesting to explore training the networks with a more powerful machine, allowing for longer sequences and larger potential network sizes. 